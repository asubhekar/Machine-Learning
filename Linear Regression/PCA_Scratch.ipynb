{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40fa987",
   "metadata": {},
   "source": [
    "# Logistic Regression, Stochastic Gradient, Mini Batch Gradient Descent\n",
    "## Name = Atharv Subhekar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0b0a59",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "92178b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# algorithm libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22f8c51",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "24b70bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'wdbc.data.csv'\n",
    "names = ['ID', 'diagnosis']\n",
    "for i in range(1, 31):\n",
    "    names.append(str(i))\n",
    "df = pd.read_csv(data, names = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c9beeff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID diagnosis      1      2       3       4        5        6       7  \\\n",
       "0    842302         M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517         M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903         M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301         M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402         M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "         8  ...     21     22      23      24      25      26      27      28  \\\n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       29       30  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f3f732f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['diagnosis']\n",
    "df = df.drop(columns = ['ID', 'diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6b6fd888",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.replace('B', -1, inplace = True)\n",
    "target.replace('M', 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a382a816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c132fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size = 0.2)\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5744e71e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c284db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(w, x):\n",
    "    numerator = 1\n",
    "    denominator = 1 + np.exp(-np.dot(w.T, x))\n",
    "    \n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "135b77de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(w, x, y):\n",
    "    n = x.shape[0]\n",
    "    summ = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        summ += (sigmoid(w, x) - y) * x\n",
    "        \n",
    "    return -summ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274ae616",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f8353c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient(w, x, y):\n",
    "    n = x.shape[0]\n",
    "    summ = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        summ += (sigmoid(w, x) - y) * x\n",
    "        \n",
    "    return -summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6c2b57e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(x, y, learning_rate, w, max_epoch=100):\n",
    "    while max_epoch > 0:\n",
    "        for i in range(x.shape[0]):\n",
    "            grad = stochastic_gradient(w, x[i], y[i])\n",
    "        w = w - grad * learning_rate \n",
    "        \n",
    "        max_epoch = max_epoch - 1\n",
    "        \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "036fede2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/bwyqsmld7671hhvbb50f731m0000gn/T/ipykernel_15321/228969756.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  denominator = 1 + np.exp(-np.dot(w.T, x))\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros((X_train.shape[1]))\n",
    "w_sgd = sgd(X_train, y_train, 0.01, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c280e982",
   "metadata": {},
   "source": [
    "### Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ae7e6e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_gradient(w, x, y):\n",
    "    summ = 0\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        summ += np.dot((sigmoid(w, x[i]) - y[i]),x[i])\n",
    "        \n",
    "    return summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a3dd0604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batches(x, y, batch_size = 10):\n",
    "    indices = [i for i in range(x.shape[0])]\n",
    "    np.random.shuffle(indices)\n",
    "    mini_batch = []\n",
    "    i = 0\n",
    "    while i < x.shape[0]:\n",
    "        mini_batch.append(indices [i : i + batch_size -1])\n",
    "        i = i + batch_size\n",
    "    \n",
    "    return mini_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d730c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbgd(x, y, learning_rate, w, max_epoch=100):\n",
    "    i = 0\n",
    "    while max_epoch > 0:\n",
    "        mini = create_mini_batches(x, y, 10)\n",
    "        for batches in mini:\n",
    "            x_mini = [x[i] for i in batches]\n",
    "            y_mini = [y[i] for i in batches]\n",
    "    \n",
    "            mbgrad = minibatch_gradient(w, x_mini, y_mini)\n",
    "            w = w - learning_rate * mbgrad\n",
    "        \n",
    "        max_epoch = max_epoch - 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2b40cec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/bwyqsmld7671hhvbb50f731m0000gn/T/ipykernel_15321/228969756.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  denominator = 1 + np.exp(-np.dot(w.T, x))\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros((X_train.shape[1]))\n",
    "w_mbgd = mbgd(X_train, y_train, 0.01, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e678a6",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7a07e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x_train, y_train, x_test, y_test, gradient_descent = 'mbgd'):\n",
    "    #list for storing folds\n",
    "    train_fold = list()\n",
    "    test_fold = list()\n",
    "    \n",
    "    # kfold\n",
    "    kf = KFold(n_splits = 5)\n",
    "    \n",
    "    # getting indices of data in each fold\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
    "        train_fold.append(list(train_index))\n",
    "        test_fold.append(list(test_index))\n",
    "        \n",
    "    # Calculating weights\n",
    "    for i in range(len(train_fold)):\n",
    "        train_data = [x_train[j] for j in train_fold[i]]\n",
    "        train_labels = [y_train[j] for j in train_fold[i]]\n",
    "        \n",
    "        test_data = [x_train[j] for j in test_fold[i]]\n",
    "        test_labels = [y_train[j] for j in test_fold[i]]\n",
    "        \n",
    "        weights = np.zeros((x_train.shape[1]))\n",
    "        wsgd = sgd(np.asarray(train_data), np.asarray(train_labels), 0.01, weights)\n",
    "        wmbgd = mbgd(np.asarray(train_data), np.asarray(train_labels), 0.01, weights)\n",
    "        \n",
    "        # predicting target and evaluating accuracy\n",
    "        y_predicted_sgd = []\n",
    "        y_predicted_mbgd = []\n",
    "        for x in test_data:\n",
    "            y_pred_sgd = np.dot(wsgd.T, x)\n",
    "            y_pred_mbgd = np.dot(wmbgd.T, x)\n",
    "            \n",
    "            if y_pred_sgd > 1:\n",
    "                y_predicted_sgd.append(1)\n",
    "            else:\n",
    "                y_predicted_sgd.append(-1)\n",
    "            if y_pred_mbgd > 1:\n",
    "                y_predicted_mbgd.append(1)\n",
    "            else:\n",
    "                y_predicted_mbgd.append(-1)\n",
    "        #Metrics for SGD        \n",
    "        t_pos_sgd = 1\n",
    "        t_neg_sgd = 1\n",
    "        f_pos_sgd = 1\n",
    "        f_neg_sgd = 1\n",
    "        \n",
    "        for i in range(len(y_predicted_sgd)):\n",
    "            if y_predicted_sgd[i] > 0 and test_labels[i] > 0:\n",
    "                t_pos_sgd += 1\n",
    "            if y_predicted_sgd[i] > 0 and test_labels [i] < 0:\n",
    "                f_pos_sgd += 1\n",
    "            if y_predicted_sgd[i] < 0 and test_labels[i] > 0:\n",
    "                f_neg_sgd += 1\n",
    "            if y_predicted_sgd[i] < 0 and test_labels[i] < 0:\n",
    "                t_neg_sgd += 1\n",
    "        \n",
    "        # Calculated precision score from confusion matrix\n",
    "        sgd_prec = []\n",
    "        sgd_rec = []\n",
    "        sgd_acc = []\n",
    "        \n",
    "        sgd_rec.append(t_pos_sgd / (t_pos_sgd + f_neg_sgd))\n",
    "        sgd_prec.append(t_pos_sgd / (t_pos_sgd + f_pos_sgd))\n",
    "        sgd_acc.append(t_pos_sgd + t_neg_sgd / t_pos_sgd + t_neg_sgd + f_pos_sgd + f_neg_sgd)\n",
    "        \n",
    "        \n",
    "        # Metrics for BSGD\n",
    "        t_pos_mbgd = 1\n",
    "        t_neg_mbgd = 1\n",
    "        f_pos_mbgd = 1\n",
    "        f_neg_mbgd = 1\n",
    "        \n",
    "        for i in range(len(y_predicted_mbgd)):\n",
    "            if y_predicted_mbgd[i] > 0 and test_labels[i] > 0:\n",
    "                t_pos_mbgd += 1\n",
    "            if y_predicted_mbgd[i] > 0 and test_labels [i] < 0:\n",
    "                f_pos_mbgd += 1\n",
    "            if y_predicted_mbgd[i] < 0 and test_labels[i] > 0:\n",
    "                f_neg_mbgd += 1\n",
    "            if y_predicted_mbgd[i] < 0 and test_labels[i] < 0:\n",
    "                t_neg_mbgd += 1\n",
    "        \n",
    "        # lists for storing data\n",
    "        mbgd_prec = []\n",
    "        mbgd_rec = []\n",
    "        mbgd_acc = []\n",
    "        \n",
    "        mbgd_rec.append(t_pos_mbgd / (t_pos_mbgd + f_neg_mbgd))\n",
    "        mbgd_prec.append(t_pos_mbgd / (t_pos_mbgd + f_pos_mbgd))\n",
    "        mbgd_acc.append(t_pos_mbgd + t_neg_mbgd / t_pos_mbgd + t_neg_mbgd + f_pos_mbgd + f_neg_mbgd)\n",
    "                \n",
    "        \n",
    "    if gradient_descent == 'mbgd':\n",
    "        return mbgd_rec, mbgd_prec, mbgd_acc\n",
    "    else:\n",
    "        return sgd_rec, sgd_prec, sgd_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1299114d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/bwyqsmld7671hhvbb50f731m0000gn/T/ipykernel_15321/228969756.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  denominator = 1 + np.exp(-np.dot(w.T, x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  [0.9696969696969697]\n",
      "Precision:  [0.34408602150537637]\n",
      "Accuracy:  [95.03125]\n",
      "Recall:  [0.2727272727272727]\n",
      "Precision:  [0.9]\n",
      "Accuracy:  [101.77777777777777]\n"
     ]
    }
   ],
   "source": [
    "#evaluate SGD and MBGD\n",
    "rec, prec, acc = evaluate(X_train, y_train, X_test, y_test, \"sgd\")\n",
    "print(\"Recall: \", rec)\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Accuracy: \", acc)\n",
    "rec_mbgd, prec_mbgd, acc_mbgd = evaluate(X_train, y_train, X_test, y_test, \"mbgd\")\n",
    "print(\"Recall: \", rec_mbgd)\n",
    "print(\"Precision: \", prec_mbgd)\n",
    "print(\"Accuracy: \", acc_mbgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1e9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
