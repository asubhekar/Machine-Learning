# -*- coding: utf-8 -*-
"""Least Squares Approximation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GLwAr-j6i2mfnbkShL97Zh4cwAWn66me

## Least Squares Approximation: Salary v. Experience

1. Import the necessary libraries. For this assignment, we'll need `numpy`, `matplotlib.pyplot`, and `pandas`. For some of the longer module names, remember we can alias them using `as` to make their types easier to work with.
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""2. Open and load the CSV file `Salary_Data.csv` into a Pandas dataframe. Name the dataframe variable something unique, like 'data' or 'df'. Remember that for CSV files, there's a built-in Pandas function for reading their data."""

df = pd.read_csv('salary_data.csv')
print(df)

"""3. Use the dataframe you created to print the first 5 items (the 'head') to the output. Utilize Pandas' built-in functions for this!"""

df.head(5)

"""4. Create a scatter plot using the Pandas dataframe. Make the X-axis years of experience, and the Y-axis the corresponding salary. Output the result. If you've done everything up to this point correctly, it should look like the following image:

    ![](o1.png)
"""

df.plot(kind = 'scatter', x = 'YearsExperience', y = 'Salary')

"""5. Implement the Least Squares approximation, to find a straight line that best approximates the data we've been provided with and plotted in the previous question. We'll be implementing this system manually - you're **not** allowed to use an external library like `numpy.linalg` to solve. You will, however, want to use the `numpy` constructions for numbers and matrices we already imported to manipulate your data.

    > As a refresher, the Least Squares Approximation finds values $\theta_0, \theta_1$ such that $y = \theta_0 + \theta_1x$ is an accurate approximation of the trend of the data provided.
    >
    > In matrix form:
    > $$A = [1 , X]$$
    >
    > $A$ can be thought of as a column of $1$'s and a column of sample $x$ values. Then, we define $\theta$ as:
    >
    > $$\theta = [\theta_0, \theta_1]^t$$
    >
    > So $b = A \theta$
    >
    > To find the approximate result, we can use the pseudo-inverse of $A$:
    > $$\theta = [(A^t A)^{(-1)} A^t] b$$
"""

array_1 = np.array([np.ones(df.shape[0]),df.YearsExperience]).T
multi = np.matmul(array_1.T,array_1)
inverse = np.linalg.inv(multi)

multi_2 = np.matmul(inverse, array_1.T)
#print(array_1)
#print(multi)
#print(inverse)
#print(multi_2)

array_2 = np.array(df.Salary)
print(array_2)

theta = np.matmul(multi_2, array_2)
theta[0]

"""6. On top of the scatter plot you created in part **4**, we now want to use our calculated $\theta$ to draw our approximate linear regression onto the plot surface. Start with the plot from earlier, and then use the `matplotlib.pyplot.plot` function to plot the predicted line from an array of $x_{pred}$ and $y_{pred}$ predictions. You'll need to likely compute $A$ for each section of the line in order to compute $y=A \cdot \theta$ for a given point - think about how you can use Numpy and matrices to calculate all of the points in the line at once!

    If you've correctly set up your linear regression, as the end result you should see something that looks like this:

    ![](o2.png)
"""

y_pred = (df.YearsExperience * theta[1]) + theta[0]

plt.scatter(x = df.YearsExperience, y = df.Salary)
plt.plot(df.YearsExperience, y_pred)
plt.show()