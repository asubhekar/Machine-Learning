# -*- coding: utf-8 -*-
"""Expectation_Maximization_GMM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UHwCX1gTAgjhdwJ1huhlE9aaDXdFBz7l

# Gaussian Mixture Models

**Notation**:

- n    : number of training points
- f    : number of features
- k    : number of gaussians
- X    : n x f matrix of training data
- r    : n x k matrix of membership weights
- pie  : k x 1 matrix of mixture weights (gaussian prior probabilities)
- mu   : k x f matrix containing the means of each gaussian
- sigma: f x f x k tensor of covariance matrices

## Importing Libraries
"""

import numpy as np
from scipy.stats import multivariate_normal

"""## Data Preprocessing"""

# training data
X = np.genfromtxt('points.dat.txt', delimiter = ' ')
print("n x f matrix of training data :",X.shape)

"""## Problem 1

Expectation: Complete the function [洧륳 = 洧냦洧논洧녷洧뉧롐넗롐뫯롐뀛롐뫯롐뒳롐럻롐(洧녦, 洧녲, 洧랢, 洧랞, 풖). This function takes in a set
of parameters of a gaussian mixture model, and outputs the membership weights of each data point
"""

def Expectation(X, k, pie, mu, sigma):
    # initializing the weights
    r = np.zeros((X.shape[0], k))
    # Calculating weights
    for i in range(k):
        probability= multivariate_normal.pdf(X, mean = mu[i, :])
        r[:, i] = pie[i] * probability
        r = r / np.sum(r, axis = 1, keepdims = True)

    return r

"""## Problem 2

Maximization of Means: Complete the function [洧랞] = 洧洧녩洧논洧녰洧녴洧녰洧녾洧뉧롐洧뉧롐뀛롐(洧녦, 洧녲, 洧). This function
takes in the training data along with the membership weights, and calculates the new maximum
likelihood mean for each gaussian
"""

def MaximizeMean(X, k, r):
    # Storing the mean and finding the maximum value of mean
    mu = []
    for i in range(k):
        product = np.dot(r[:, i], X)
        product = product / np.sum(r[:, i])
        mu.append(product)

    mu = np.array(mu)
    return mu

"""## Problem 3

Maximization of Covariances: Complete the function [풖] = 洧洧녩洧논洧녰洧녴洧녰洧녾洧뉧롏윓롐럻롐洧녩洧洧녰洧녩洧녵洧녫洧(洧녦, 洧녲, 洧, 洧랞).
This function takes in the training data along with membership weights and means for each gaussian,
and calculates the new maximum likelihood covariance for each gaussian
"""

def MaximizeCovariance(X, k, r, mu):
    # initializing covariances
    sigma = np.random.rand(2, 2, 3)
    # maximizing covariances
    for i in range(k):
        prod = np.dot(X - mu[i], (X - mu[i]).T)
        mul = np.sum(r[:, i] * prod)
        sigma[:, :, i] = mul / np.sum(r[:, i])
    return sigma

"""## Problem 4

Maximization of Mixture Weights: Complete the function [洧랢] = 洧洧녩洧논洧녰洧녴洧녰洧녾洧뉧롐洧녰洧논洧노洧녹洧洧뉧롐(洧녲, 洧).
This function takes in the membership weights, and calculates the new maximum likelihood
mixture weight for each gaussian
"""

def MaximizeMixtures(k, r):
    # initializing mixtures
    pi = []
    # maximizing mixtures
    for i in range(k):
        pi.append(np.sum(r[:, i]) / r.shape[0])
    # converting list to numpy array
    pi = np.array(pi)
    return pi

"""## Problem 5

EM: Put everything together and implement the function [洧랢, 洧랞, 풖] = 洧냦洧(洧녦, 洧녲, 洧랢% , 洧랞% , 풖% , 洧녵洧냪洧노洧뉧롐).
This function runs the EM algorithm for 洧녵洧냪洧노洧뉧롐 steps/iterations and returns the parameters of the
underlying GMM.
"""

def EM(X, k, pi, mu, sigma, Iters):
    # iterating for nIter times
    while Iters > 0:
        #obtaining the membership weights
        r = Expectation(X, k, pi, mu, sigma)
        # obtaining maximized means
        mu = MaximizeMean(X, k, r)
        # obtaining maximized covariances
        sigma = MaximizeCovariance(X, k, r, mu)
        # obtaining maximized mixtures
        pi = MaximizeMixtures(k, r)
        Iters -= 1
    return pi, mu, sigma

"""## Main Block"""

# initializing parameters
mu0 = np.random.rand(3, 2)
pie0 = np.random.rand(3, 1)
sigma0 = np.random.rand(2, 2, 3)
k = 3
# calling EM function
pi, mu, sigma = EM(X, k, pie0, mu0, sigma0, 1)
# printing results
print("Shape of Mixture Weights:", pi.shape)
print("\n", pi)

print("\n Gaussian Mean")
print("Shape: ", mu.shape)
print(mu)

print("\n Tensor of Covariances")
print("Shape: ", sigma.shape)
print(sigma)

