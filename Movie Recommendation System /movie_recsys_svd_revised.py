# -*- coding: utf-8 -*-
"""Movie_RecSys_SVD_Revised.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wer7fTDfXgDWX8YuAFDbv71iqWgoRwuz

# Movie Recommendations

**Name:**

**Collaboration Policy:** Homeworks will be done individually: each student must hand in their own answers. Use of partial or entire solutions obtained from others or online is strictly prohibited.

**Late Policy:** Late submission have a penalty of 2\% for each passing hour.

**Submission format:** Successfully complete the Movie Lens recommender as described in this jupyter notebook. Submit a `.py` and an `.ipynb` file for this notebook. You can go to `File -> Download as ->` to download a .py version of the notebook.

**Only submit one `.ipynb` file and one `.py` file.** The `.ipynb` file should have answers to all the questions. Do *not* zip any files for submission.

**Download the dataset from here:** https://grouplens.org/datasets/movielens/1m/
"""

# Import all the required libraries
import numpy as np
import pandas as pd

"""## Reading the Data
Now that we have downloaded the files from the link above and placed them in the same directory as this Jupyter Notebook, we can load each of the tables of data as a CSV into Pandas. Execute the following, provided code.
"""

# Read the dataset from the two files into ratings_data and movies_data
column_list_ratings = ["UserID", "MovieID", "Ratings","Timestamp"]
ratings_data  = pd.read_csv('ratings.dat',sep='::',names = column_list_ratings, encoding = 'ISO-8859-1', engine = 'python')
column_list_movies = ["MovieID","Title","Genres"]
movies_data = pd.read_csv('movies.dat',sep = '::',names = column_list_movies, encoding = 'ISO-8859-1', engine = 'python')
column_list_users = ["UserID","Gender","Age","Occupation","Zixp-code"]
user_data = pd.read_csv("users.dat",sep = "::",names = column_list_users, encoding = 'ISO-8859-1', engine = 'python')

"""`ratings_data`, `movies_data`, `user_data` corresponds to the data loaded from `ratings.dat`, `movies.dat`, and `users.dat` in Pandas.

## Data analysis

We now have all our data in Pandas - however, it's as three separate datasets! To make some more sense out of the data we have, we can use the Pandas `merge` function to combine our component data-frames. Run the following code:
"""

data=pd.merge(pd.merge(ratings_data,user_data),movies_data)
data

"""Next, we can create a pivot table to match the ratings with a given movie title. Using `data.pivot_table`, we can aggregate (using the average/`mean` function) the reviews and find the average rating for each movie. We can save this pivot table into the `mean_ratings` variable."""

mean_ratings=data.pivot_table('Ratings','Title',aggfunc='mean')
mean_ratings

"""Now, we can take the `mean_ratings` and sort it by the value of the rating itself. Using this and the `head` function, we can display the top 15 movies by average rating."""

mean_ratings=data.pivot_table('Ratings',index=["Title"],aggfunc='mean')
top_15_mean_ratings = mean_ratings.sort_values(by = 'Ratings',ascending = False).head(15)
top_15_mean_ratings

"""Let's adjust our original `mean_ratings` function to account for the differences in gender between reviews. This will be similar to the same code as before, except now we will provide an additional `columns` parameter which will separate the average ratings for men and women, respectively."""

mean_ratings=data.pivot_table('Ratings',index=["Title"],columns=["Gender"],aggfunc='mean')
mean_ratings

"""We can now sort the ratings as before, but instead of by `Rating`, but by the `F` and `M` gendered rating columns. Print the top rated movies by male and female reviews, respectively."""

data=pd.merge(pd.merge(ratings_data,user_data),movies_data)

mean_ratings=data.pivot_table('Ratings',index=["Title"],columns=["Gender"],aggfunc='mean')
top_female_ratings = mean_ratings.sort_values(by='F', ascending=False)
print(top_female_ratings.head(15))

top_male_ratings = mean_ratings.sort_values(by='M', ascending=False)
print(top_male_ratings.head(15))

mean_ratings['diff'] = mean_ratings['M'] - mean_ratings['F']
sorted_by_diff = mean_ratings.sort_values(by='diff')
sorted_by_diff[:10]

"""Let's try grouping the data-frame, instead, to see how different titles compare in terms of the number of ratings. Group by `Title` and then take the top 10 items by number of reviews. We can see here the most popularly-reviewed titles."""

ratings_by_title=data.groupby('Title').size()
ratings_by_title.sort_values(ascending=False).head(20)

"""Similarly, we can filter our grouped data-frame to get all titles with a certain number of reviews. Filter the dataset to get all movie titles such that the number of reviews is >= 2500.

## Question 1

Create a ratings matrix using Numpy. This matrix allows us to see the ratings for a given movie and user ID. Every element $[i,j]$ is a rating by user $i$ for movie $j$. Print the **shape** of the matrix produced.

**Notes:**
- Do *not* use `pivot_table`.
- A ratings matrix is *not* the same as `ratings_data` from above.
- If you're stuck, you might want to look into the `np.ndarray` datatype and how to create one of the desired shape.
- Every review lies between 1 and 5, and thus fits within a `uint8` datatype, which you can specify to numpy.
"""

# Create the matrix
ratings = np.ndarray(((max(user_data.UserID)+1),(max(movies_data.MovieID)+1)), dtype='uint8')

for k in range(len(ratings_data)):
   ratings[ratings_data.UserID[k]][ratings_data.MovieID[k]] = ratings_data.Ratings[k]
#print(ratings)

# Print the shape
ratings.shape

ratings

"""## Question 2

Normalize the ratings matrix (created in **Question 1**) using Z-score normalization. While we can't use `sklearn`'s `StandardScaler` for this step, we can do the statistical calculations ourselves to normalize the data.

Before you start:
- All of the `NaN` values in the dataset should be replaced with the average rating for the given movie. This is a complex topic, but for our case replacing empty values with the mean will make it so that the absence of a rating doesn't affect the overall average, and it provides an "expected value" which is useful for computing correlations and recommendations in later steps.
- Your first step should be to get the average of every *column* of the ratings matrix (we want an average by title, not just by user!).
- Second, we want to subtract the average from the original ratings thus allowing us to get a mean of 0 in every row. It may be very close but not exactly zero because of the limited precision `float`s allow.
- Lastly, divide this by the standard deviation of the *column*

- While creating the ratings matrix, you might not get any NaN values but if you look closely, you will see 0 values. This should be treated as NaN values as the original data does not have 0 rating. This should be replaced by the average.
"""

ratings_mean = np.mean(ratings, axis = 0)

ratings = ratings - ratings_mean
ratings = ratings / np.std(ratings, axis = 0)
ratings = np.nan_to_num(ratings)
print(ratings)

"""## Question 3

We're now going to perform Singular Value Decomposition (SVD) on the normalized ratings matrix from the previous question. Perform the process using numpy, and along the way print the shapes of the $U$, $S$, and $V$ matrices you calculated.
"""

# Compute the SVD of the normalised matrix

U, S, V = np.linalg.svd(ratings)

# Print the shapes
print(U.shape)
print(S.shape)
print(V.shape)

"""## Question 4

Reconstruct four rank-k rating matrix $R_k$, where $R_k = U_kS_kV_k^T$ for k = [100, 1000, 2000, 3000]. Using each of $R_k$ make predictions for 3 users (select them from the dataset) for the movie with ID 1377 (Batman Returns).
"""

k = 1000
U_1000 = U[:, 0:k]

S_1000 = S[0:k]
S_1000 = np.diag(S_1000)

V_1000 = V[:, 0:k]
V_1000 = V_1000.transpose()

print(U_1000.shape)
print(S_1000.shape)
print(V_1000.shape)

k = 100
U_100 = U[:, 0:k]

S_100 = S[0:k]
S_100 = np.diag(S_100)

V_100 = V[:, 0:k]
V_100 = V_100.transpose()

print(U_100.shape)
print(S_100.shape)
print(V_100.shape)

k = 2000
U_2000 = U[:, 0:k]

S_2000 = S[0:k]
S_2000 = np.diag(S_2000)

V_2000 = V[:, 0:k]
V_2000 = V_2000.transpose()

print(U_2000.shape)
print(S_2000.shape)
print(V_2000.shape)

k = 3000
U_3000 = U[:, 0:k]

S_3000 = S[0:k]
S_3000 = np.diag(S_3000)

V_3000 = V[:, 0:k]
V_3000 = V_3000.transpose()

print(U_3000.shape)
print(S_3000.shape)
print(V_3000.shape)

res = np.matmul(np.matmul(U_1000, S_1000), V_1000)

"""## Question 5

### Cosine Similarity
Cosine similarity is a metric used to measure how similar two vectors are. Mathematically, it measures the cosine of the angle between two vectors projected in a multi-dimensional space. Cosine similarity is high if the angle between two vectors is 0, and the output value ranges within $cosine(x,y) \in [0,1]$. $0$ means there is no similarity (perpendicular), where $1$ (parallel) means that both the items are 100% similar.

$$ cosine(x,y) = \frac{x^T y}{||x|| ||y||}  $$

**Based on the reconstruction rank-1000 rating matrix $R_{1000}$ and the cosine similarity,** sort the movies which are most similar. You will have a function `top_cosine_similarity` which sorts data by its similarity to a movie with ID `movie_id` and returns the top $n$ items, and a second function `print_similar_movies` which prints the titles of said similar movies. Return the top 5 movies for the movie with ID `1377` (*Batman Returns*):
"""

# Sort the movies based on cosine similarity
def top_cosine_similarity(data, movie_id, top_n=5):
    # Movie id starts from 1
    #Use the calculation formula above
    movie_id = movies_data[movies_data['MovieID']==movie_id].index.values[0]

    sim = (data[:, movie_id] @ data) / (np.linalg.norm(data[:, movie_id]) * np.linalg.norm(data))
    sim = list(sim)

    sim_sorted = sorted(sim, reverse = True)[1:6]
    top_n = []

    for val in sim_sorted:
        top_n.append(sim.index(val))

    return top_n


def print_similar_movies(movie_data,movieID,top_indexes):
    index_of_movie = movies_data.Title[movies_data[movies_data['MovieID']==movieID].index.values[0]]
    print('Most Similar movies to {}: \n'.format(index_of_movie))
    for ind in top_indexes:
        print(movies_data.Title[movies_data[movies_data['MovieID']==ind].index.values[0]])

# Print the top 5 movies for Batman Returns
movie_id = 1377
top_indexes = top_cosine_similarity(res, movie_id)
print_similar_movies(movies_data, movie_id, top_indexes)

