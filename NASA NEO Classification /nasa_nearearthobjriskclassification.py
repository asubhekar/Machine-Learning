# -*- coding: utf-8 -*-
"""NASA_NearEarthObjRiskClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1msS4S_FT8tQYJ85OHxsJfmwgL4vpCXua

# Importing Libraries
"""

# preprocessing libraries
import pandas as pd
import numpy as np
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import Normalizer

# algorithm libraries
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.decomposition import PCA

# metric libraries
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score

# plotting libraries
import matplotlib.pyplot as plt

"""# Preprocessing Dataset"""

# loading dataset
dataset = pd.read_csv('NASA.csv')
dataset.head()

# dropping unwanted columns
# these columns do not contribute towards the prediction of the target and hence can be dropped
dataset = dataset.drop(columns = ['id', 'name', 'orbiting_body', 'sentry_object'])
dataset.head()

# splitting dataset into features and target
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

# label encoding the target column
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# splitting dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, train_size=0.8, random_state=0)

# visualizing the features
fig, ax = plt.subplots(5, 1, figsize = (8, 20))
columns = list(dataset.columns)

for i in range(len(columns)-1):
    ax[i].plot(dataset[columns[i]])
    ax[i].set_title(columns[i])

"""On visualizing the features, we can observe that the range of features is not standardized. Due to this, one feature can prove to be heavier or more decisive than other feature. This could affect the overall performance of the model. Hence, to avoid this we will standardize the features so that they will be in the same range"""

# feature scaling
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""# Logistic Regression"""

# logistic regression
logisticRegression = LogisticRegression()
logisticRegression.fit(X_train, y_train)

y_pred_lr = logisticRegression.predict(X_test)

# logistic regression metrics
lr_precision = precision_score(y_test, y_pred_lr)
lr_recall = recall_score(y_test, y_pred_lr)
lr_f1 = f1_score(y_test, y_pred_lr)

print("Accuracy: ", accuracy_score(y_test, y_pred_lr))
print("Precision: ", lr_precision)
print("Recall: ", lr_recall)
print("F1 Score: ", lr_f1)

"""# Support Vector Classification"""

# support vector classification
svc = LinearSVC(loss = 'squared_hinge', dual = True)
svc.fit(X_train, y_train)

y_pred_svc = svc.predict(X_test)

# support vector classification metrics
svc_precision = precision_score(y_test, y_pred_svc)
svc_recall = recall_score(y_test, y_pred_svc)
svc_f1 = f1_score(y_test, y_pred_svc)

print("Accuracy: ", accuracy_score(y_test, y_pred_svc))
print("Precision: ", svc_precision)
print("Recall: ", svc_recall)
print("F1 Score: ", svc_f1)

"""# PCA"""

# pca model
pca = PCA(n_components = 2)

# fitting features to pca model
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

"""### Logistic Regression (PCA)"""

# training logistic regression using pca
logisticRegression.fit(X_train_pca, y_train)
y_pred_lr_pca = logisticRegression.predict(X_test_pca)

# logistic regression metrics (pca)
lr_precision_pca = precision_score(y_test, y_pred_lr_pca)
lr_recall_pca = recall_score(y_test, y_pred_lr_pca)
lr_f1_pca = f1_score(y_test, y_pred_lr_pca)


print("Accuracy: ", accuracy_score(y_test, y_pred_lr_pca))
print("Precision: ", lr_precision_pca)
print("Recall: ", lr_recall_pca)
print("F1 Score: ", lr_f1_pca)

"""### Support Vector Classification (PCA)"""

# training svc using pca
svc.fit(X_train_pca, y_train)
y_pred_svc_pca = svc.predict(X_test_pca)

# svc metrics (pca)
svc_precision_pca = precision_score(y_test, y_pred_svc_pca)
svc_recall_pca = recall_score(y_test, y_pred_svc_pca)
svc_f1_pca = f1_score(y_test, y_pred_svc_pca)

print("Accuracy: ", accuracy_score(y_test, y_pred_svc_pca))
print("Precision: ", svc_precision_pca)
print("Recall: ", svc_recall_pca)
print("F1 Score: ", svc_f1_pca)