# -*- coding: utf-8 -*-
"""Decision_Tree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GPxbF_8SQqQGrPDkIUpU0ghAEUjj1nag

## Decision Tree
"""

#import preprocessing libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#algorithm libraries
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn import tree
from sklearn.model_selection import GridSearchCV

#Metrics libraries
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix

"""### Data Preprocessing"""

data = pd.read_csv('Titanic.csv')
data

# Storing the target labels
target = data['survived']
# Storing needed columns from the data
features = data.drop(columns = ['Unnamed: 0','survived','name','parch','ticket','fare','cabin','embarked','boat','body','home.dest'])

"""During data preprocessing, I found several NaN values which I replaced with the mean values in that column. This gave me better result than just randomly filling the data in those locations."""

# Fill all the null values with the mean of that column
features['age'].fillna(features['age'].mean(), inplace=True)
# Replacing all the female and male entries with 1 and -1 to fit the model
features['sex'].replace('female', -1, inplace = True)
features['sex'].replace('male', 1, inplace = True)
# Replacing all the pclass entries with integers 1,2,3
features['pclass'].replace('1st', 1, inplace = True)
features['pclass'].replace('2nd', 2, inplace = True)
features['pclass'].replace('3rd', 3, inplace = True)

print('Final dataset after pre processing')
features

print('Final target labels after pre processing')
target

"""### Splitting the dataset
Splitting the dataset into 70% training set and 30% testing set.
"""

#Splitting the data into training set and testing set
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3)

print('X_train shape = ',X_train.shape)
print('y_train shape = ',y_train.shape)
print('X_test shape = ',X_test.shape)
print('y_test shape = ',y_test.shape)

"""### Decision Tree Classifier"""

# Initializing the model
decision_tree = tree.DecisionTreeClassifier(random_state = 42)
# Fitting the model on training data
decision_tree.fit(X_train,y_train)
# Predicting the labels values using the test data
y_pred = decision_tree.predict(X_test)
# Evaluating the model
dtree_accuracy = accuracy_score(y_pred, y_test)
# Priting the accuracy of Decision Tree Classifier
print(dtree_accuracy)
print(f'Decision Tree Accuracy: {dtree_accuracy*100:.2f}%')

# Printing the text representation of the tree for understanding
text_representation = tree.export_text(decision_tree)
print(text_representation)

# Plotting the full tree
plt.figure(figsize=(20,15))
tree.plot_tree(decision_tree,feature_names=X_train.columns, class_names=['No', 'Yes'],fontsize=5,filled=True)
plt.show()

"""### Grid Search Cross Validation
We will be using grid search cross validation to find the best parameters of tree nodes and check over accuracy.
"""

# Setting the parameters to optimize using grid search CV
param_grid = {'max_leaf_nodes': [None, 2, 3,4,5,6,7,8,9]}
# Initializing grid search CV
grid_search = GridSearchCV(decision_tree, param_grid, cv=5, scoring='accuracy')
# Fitting grid search CV on training data
grid_search.fit(X_train, y_train)
# Priting best parameters based on accuracy score
print(f'Improved score: {grid_search.best_score_*100:.2f}%')
print('Improved parameters: ', grid_search.best_params_)
best_param = grid_search.best_params_['max_leaf_nodes']

# Plot the graph
plt.figure()
plt.plot(max_depth, 1-results['mean_test_score'], marker='o', linestyle='-')
plt.xlabel("Tree Size")
plt.ylabel("Misclassified")
plt.title("Tree Size vs. Misclassification Rate")
plt.grid(True)
plt.show()

"""I tried calculating the number of misclassifications by manually passing all the parameters. But the achieved plot is a little different since in GridSearch CV, we are using small batches for cross validation. In this case we used 5 batches.
If we use K fold cross validation followed by Decision Tree Classifier we might get closer output. But finally it comes down to the shuffling of data elements during the process.
In general, the plot show the same trend and are approximately correct.
"""

# To plot a graph for misclassified elements vs tree size.
# Creating a list of parameters (max_leaf_nodes)
max_depth = param_grid['max_leaf_nodes']
# Creating a list to store the number of misclassified elements using all combinations of parameters.
misclassed = []
# Looping through all the parameters manually to store the wrong predictions
for size in max_depth:
  count = 0
  dtree_sizewise = DecisionTreeClassifier(random_state = 42, max_leaf_nodes=size)
  dtree_sizewise.fit(X_train,y_train)
  y_pred = dtree_sizewise.predict(X_train)
  # Checking for correct predictions using boolean flags
  predictions = (y_pred==y_train)
  # Counting the number of False flags
  for pred in predictions:
    if pred == False:
      count+=1
  # Appending all the counts in a list.
  misclassed.append(count)

# Plot the graph
plt.figure()
plt.plot(max_depth, misclassed, marker='o', linestyle='-')
plt.xlabel("Tree Size")
plt.ylabel("Misclassified")
plt.title("Tree Size vs. Number of Missclassifications")
plt.grid(True)
plt.show()

"""### Decision Tree Classifier using the best parameters."""

# Initializing the model
decision_tree_optimized = tree.DecisionTreeClassifier(max_leaf_nodes=best_param)
# Fitting the model on training data
decision_tree_optimized.fit(X_train,y_train)
# Predicting the labels values using the test data
y_pred = decision_tree_optimized.predict(X_test)
# Evaluating the model
dtreeopt_accuracy = accuracy_score(y_pred, y_test)
# Priting the accuracy of Decision Tree Classifier
print(f'Optimized Decision Tree Accuracy: {dtreeopt_accuracy *100:.2f}%')

# Plotting the pruned tree
plt.figure(figsize=(10,10))
tree.plot_tree(decision_tree_optimized,filled=True)
plt.show()

# Report percent survivors and fatalities correctly predicted on the test set
predictions = decision_tree_optimized.predict(X_test)
survivors_correct = np.sum((predictions == 1) & (y_test == 1))
fatalities_correct = np.sum((predictions == 0) & (y_test == 0))
total_survivors = np.sum(y_test == 1)
total_fatalities = np.sum(y_test == 0)

percent_survivors_correct = (survivors_correct / total_survivors) * 100
percent_fatalities_correct = (fatalities_correct / total_fatalities) * 100

print(f'Percent survivors correctly predicted: {percent_survivors_correct:.2f}%')
print(f'Percent fatalities correctly predicted: {percent_fatalities_correct:.2f}%')

"""### Random Forest Classifier

"""

random_forest = RandomForestClassifier(n_estimators=50,max_leaf_nodes=best_param)
random_forest.fit(X_train, y_train)
y_pred = random_forest.predict(X_test)
# Evaluating the model
rf_accuracy = accuracy_score(y_pred, y_test)
print(f'Optimized Random Forest Accuracy: {rf_accuracy *100:.2f}%')

# Report percent survivors and fatalities correctly predicted on the test set
predictions = random_forest.predict(X_test)
survivors_correct = np.sum((predictions == 1) & (y_test == 1))
fatalities_correct = np.sum((predictions == 0) & (y_test == 0))
total_survivors = np.sum(y_test == 1)
total_fatalities = np.sum(y_test == 0)

percent_survivors_correct = (survivors_correct / total_survivors) * 100
percent_fatalities_correct = (fatalities_correct / total_fatalities) * 100

print(f'Percent survivors correctly predicted: {percent_survivors_correct:.2f}%')
print(f'Percent fatalities correctly predicted: {percent_fatalities_correct:.2f}%')

"""### Conclusion
After plotting the full decision tree we can observe accuracy of around 76%. After using Grid Search CV, we can find the best number of lead nodes required to get the best accuracy. Using Grid Search CV gave better accuracy compared to unoptmized decision tree.

After optimizing the parameters, we get accuracy around 80% using decision tree. The accuracy of correct predicted suvivors was 72% and correct predicted fatalities was 85%.

We used the same parameters and trained Random Forest Classifier which gave accuracy of around 80%. The accuracy of correct predicted suvivors was 67% and correct predicted fatalities was 87%.

We can conclude that the optimized decision tree parameters do not give better result when used with Random Forest and random forest may perform better if the parameters are optimized separately
"""