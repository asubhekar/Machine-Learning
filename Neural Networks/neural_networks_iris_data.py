# -*- coding: utf-8 -*-
"""Neural_Networks_Iris_Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qFSyNKV-kmvkNseJCTCIikmgaWtKoXg6

# Neural Networks

## Importing Libraries
"""

!pip install sklearn

import pandas as pd
import numpy as np

#import tensorflow as tf
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras import Sequential

import matplotlib.pyplot as plt

"""## Data Preprocessing"""

# loading dataset
names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']
dataset = pd.read_csv("iris.data", names = names)

# splitting dataset into features and target
X = dataset.iloc[:,0:4].values
y = dataset.iloc[:,4].values

# label and one hot encoding target values
label_encoder =  LabelEncoder()
y = label_encoder.fit_transform(y)
y = pd.get_dummies(y).values

# splitting data into training and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)

"""## Neural Network"""

# building neural network
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
  ])

# compiling neural network
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# number of epochs
epochs = 100

# fitting the model on training set
history = model.fit(X_train, y_train, validation_split = 0.1, epochs = epochs)

"""## Performance Metrics"""

# calculating test loss and accuracy
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)

# printing results
print("Training Accuracy: ", history.history["accuracy"][-1])
print("Validation Accuracy: ", history.history["val_accuracy"][-1])
print("Testing Accuracy: ", test_accuracy)

# plotting training and validation accuracy
train_acc = history.history["accuracy"]
val_acc = history.history["val_accuracy"]

plt.figure(figsize = (10, 5))
plt.plot([i for i in range(epochs)], train_acc)
plt.plot([i for i in range(epochs)], val_acc)
plt.legend(["Training ", "Validation "])
plt.show()

# plotting training and validation loss
train_loss = history.history["loss"]
val_loss = history.history["val_loss"]

plt.figure(figsize = (10, 5))
plt.plot([i for i in range(epochs)], train_loss)
plt.plot([i for i in range(epochs)], val_loss)
plt.legend(["Training ", "Validation "])
plt.show()

"""## Prediction"""

# testing model on the test set
y_pred = model.predict(X_test)

# comparing true and predicted values
true = np.argmax(y_test,axis=1)
predicted = np.argmax(y_pred,axis=1)

print("Ground Truth: ", true)
print("Predicted: ", predicted)

